{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing the dependencies and the IMDB datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing tflearn and other helper functions\n",
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "\n",
    "# tflearn has a pre-processed dataset of IMDB movie ratings\n",
    "from tflearn.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The below command divides the IMDB dataset in to train and test datasets.I am using 10,000 words from the database and 10% is used for validation set (therefore valid_portion = 0.1)\n",
    "\n",
    "Note: load_data function downloads the data from web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test, _ = imdb.load_data(path='imdb.pkl', n_words=10000,valid_portion=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reviews and Labels are further divided into trainX,trainY and testX,testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = train\n",
    "testX, testY = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing the data\n",
    "As seen in the below cell, the text reviwes are represented as numerical values in form of matrices. This is the vector representation of each word in the text corpus using Google's Word2Vec model.\n",
    "Refer to :https://www.kaggle.com/c/word2vec-nlp-tutorial#part-2-word-vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17, 25, 10, 406, 26, 14, 56, 61, 62, 323, 4],\n",
       " [16, 586, 32, 885, 17, 39, 68, 31, 2994, 2389, 328, 4],\n",
       " [1, 2, 1, 139, 6, 130, 1, 5, 6, 25, 105, 4730, 40],\n",
       " [6691, 1, 10, 333, 10, 17, 27, 4, 34, 181, 6, 1418, 256, 4],\n",
       " [30, 287, 142, 2216, 707, 3763, 20, 68, 57, 30, 37, 309, 14, 4]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0:5] # vector representation of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY[0:5] # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train dataset reviews is:  (22500,)\n",
      "Shape of the train dataset labels is:  (22500,)\n",
      "Shape of the test dataset reviews is:  (2500,)\n",
      "Shape of the test dataset labels is:  (2500,)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print (\"Shape of the train dataset reviews is: \",numpy.array(trainX).shape)\n",
    "print (\"Shape of the train dataset labels is: \",numpy.array(trainY).shape)\n",
    "\n",
    "print (\"Shape of the test dataset reviews is: \",numpy.array(testX).shape)\n",
    "print (\"Shape of the test dataset labels is: \",numpy.array(testY).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data-Preprocessing:\n",
    "\n",
    "    1) Sequence padding - making sure each input review vector sample is of same length. \n",
    "        Any review sequence length> max length are tructuated\n",
    "        Any review sequence length< max length are padded with zeroes\n",
    "    2) Converting labels in to binary vectord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pad Sequences using helper function of tflearn - pad_sequences\n",
    "trainX = pad_sequences(trainX, maxlen=100, value=0.)\n",
    "testX = pad_sequences(testX, maxlen=100, value=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualazing the review features after padding with zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  17,   25,   10,  406,   26,   14,   56,   61,   62,  323,    4,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [  16,  586,   32,  885,   17,   39,   68,   31, 2994, 2389,  328,\n",
       "           4,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label conversion to binary vectors using to_categorical function of tflearn utils\n",
    "trainY = to_categorical(trainY,nb_classes = 2)\n",
    "testY = to_categorical(testY, nb_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the labels after binary vector conversion\n",
    "\n",
    "Note: As seen in the below cell, label \"0\" is represented as vector [1 0]. This one hot encoding is required for tflearn to handle these labels in modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Network Model\n",
    "\n",
    "        At each line, each layer of neural network is defined\n",
    "        Each layers output is next layer input\n",
    "        Every layer in the network has the hyperparameters that needs to be defined        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net1 = tflearn.input_data([None,100]) # None - is to accept as many number of samples i.e batch_size and 100 - feature size (word length here)\n",
    "net2 = tflearn.embedding(net1,input_dim = 10000, output_dim = 128)\n",
    "net3 = tflearn.lstm(net2,128,dropout = 0.8)\n",
    "net4 = tflearn.fully_connected(net3,2,activation = 'softmax')\n",
    "net5 = tflearn.regression(net4,optimizer = 'adam', learning_rate = 0.0001, loss = 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7534  | total loss: \u001b[1m\u001b[32m0.07482\u001b[0m\u001b[0m | time: 157.543s\n",
      "| Adam_0 | epoch: 011 | loss: 0.07482 - acc: 0.9875 -- iter: 22496/22500\n",
      "Training Step: 7535  | total loss: \u001b[1m\u001b[32m0.07349\u001b[0m\u001b[0m | time: 163.992s\n",
      "| Adam_0 | epoch: 011 | loss: 0.07349 - acc: 0.9856 | val_loss: 0.69186 - val_acc: 0.8096 -- iter: 22500/22500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "nn_model = tflearn.DNN(net5, tensorboard_verbose =0)\n",
    "model.fit(trainX, trainY, validation_set=(testX, testY), show_metric=True,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the model performed well on both training and testing dataset\n",
    "Accuracy on Training Dataset is 98.75%\n",
    "Accuracy on Testing Dataset is 80.96"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
